{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "410a18dd",
   "metadata": {},
   "source": [
    "# Ensambles | Desafío 1 (SDM)\n",
    "\n",
    "**Objetivo:** aplicar ensambles (RF, GB, Stacking) a un problema de clasificación y comparar métricas.\n",
    "\n",
    "**Reproducibilidad:** ejecuta este notebook dentro de la estructura del repo (`notebooks/`), con `requirements.txt` instalado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bccfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuración general del experimento ===\n",
    "PROJECT = \"Ensambles | Desafío 1\"\n",
    "SEED = 42\n",
    "TEST_SIZE = 0.2  # fracción para test\n",
    "CV = 5           # folds de validación cruzada\n",
    "TARGET = \"Churn\"  # Ajusta si tu columna objetivo tiene otro nombre\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb70699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports base ===\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# sklearn métricas y utilidades comunes\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_curve, auc, accuracy_score, precision_recall_fscore_support,\n",
    ")\n",
    "\n",
    "sns.set(context=\"notebook\", style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Utilidades de exportación seguras ===\n",
    "import os\n",
    "REPORTS_DIR = Path(\"../reports\")\n",
    "FIG_DIR = REPORTS_DIR / \"figures\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def safe_savefig(fig, path):\n",
    "    try:\n",
    "        fig.savefig(path, bbox_inches=\"tight\")\n",
    "        print(f\"[OK] Figura guardada en {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] No se pudo guardar figura en {path}: {e}\")\n",
    "\n",
    "def safe_to_csv(df, path, index=False):\n",
    "    try:\n",
    "        df.to_csv(path, index=index)\n",
    "        print(f\"[OK] CSV guardado en {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] No se pudo guardar CSV en {path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dV1m5aBo9edd"
   },
   "source": [
    "---\n",
    "\n",
    "# Desafío - Modelos de ensamble (parte I)(G93)\n",
    "\n",
    "---\n",
    "\n",
    "Este framework sigue un enfoque iterativo, aunque el trabajo se presenta de manera lineal.\n",
    "\n",
    "En la práctica, es común regresar a etapas anteriores para realizar ajustes y optimizar el proceso.\n",
    "\n",
    "Por ejemplo, puede ser necesario transformar variables antes de analizar correlaciones o generar visualizaciones significativas.\n",
    "\n",
    "Este enfoque flexible permite garantizar que cada paso contribuya de manera efectiva a la construcción de un modelo preciso y robusto.\n",
    "\n",
    "---\n",
    "\n",
    "Nombre: SERGIO C. DELGADO MARTINEZ\n",
    "\n",
    "Profesor: GABRIEL A. CESPEDES ALARCON\n",
    "\n",
    "Desafio: Detección temprana de renuncias en\n",
    "empresa de telecomunicaciones\n",
    "\n",
    "Curso: Modelos avanzados y Redes Neuronales (G93)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aDgWbl19jp7"
   },
   "source": [
    "## **Resumen Ejecutivo**\n",
    "\n",
    "El desafío propone construir y analizar distintos modelos de ensamble para la **detección temprana de renuncias de clientes** en una empresa de telecomunicaciones. Se trabaja con un dataset que contiene variables relacionadas con el comportamiento y los servicios de los clientes. El objetivo es predecir el abandono (churn) y explicar qué factores influyen más en esa decisión.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phfqBFNF9nkx"
   },
   "source": [
    "## **Contenido del Dataset (`telecom_churn.csv`)**\n",
    "\n",
    "| Variable          | Descripción                                     |\n",
    "|------------------|-------------------------------------------------|\n",
    "| `Churn`          | Variable objetivo (1 = renuncia, 0 = permanece) |\n",
    "| `AccountWeeks`   | Semanas con la cuenta activa                    |\n",
    "| `ContractRenewal`| Si renovó contrato recientemente (1/0)          |\n",
    "| `DataPlan`       | Si tiene plan de datos (1/0)                    |\n",
    "| `DataUsage`      | Uso mensual de datos (GB)                       |\n",
    "| `CustServCalls`  | Nº de llamadas al servicio al cliente           |\n",
    "| `DayMins`        | Promedio de minutos diurnos al mes              |\n",
    "| `DayCalls`       | Nº medio de llamadas diurnas                    |\n",
    "| `MonthlyCharge`  | Cargo mensual promedio                          |\n",
    "| `OverageFee`     | Máximo recargo por exceso en últimos 12 meses   |\n",
    "| `RoamMin`        | Minutos de uso en roaming                       |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8Hwcn7x9sTX"
   },
   "source": [
    "## **Tareas Específicas**\n",
    "\n",
    "### 1. **Exploración de Datos**\n",
    "- Importar librerías\n",
    "- Cargar datos\n",
    "- Visualizar variables\n",
    "- Analizar correlaciones (usar heatmap)\n",
    "\n",
    "### 2. **Árbol de Decisión**\n",
    "- Entrenar árbol sin ajustar hiperparámetros\n",
    "- Evaluar métricas\n",
    "- Optimizar con Grid Search (5-fold CV) para `max_depth` y `min_samples_split`\n",
    "- Reportar hiperparámetros óptimos y desempeño (train/test)\n",
    "\n",
    "### 3. **Bagging con SMOTE**\n",
    "- Aplicar SMOTE al set de entrenamiento para balancear clases\n",
    "- Entrenar modelo de Bagging con 200 estimadores (homogéneo)\n",
    "- Evaluar desempeño en set de test\n",
    "\n",
    "### 4. **Bagging Heterogéneo**\n",
    "- Entrenar modelo con:\n",
    "  - Regresión Logística\n",
    "  - Árbol de decisión\n",
    "  - SVM (kernel RBF)\n",
    "  - SVM (kernel Sigmoid)\n",
    "- Usar 200 muestras bootstrap\n",
    "- Evaluar f1-score y repetir el mejor modelo para calibrar importancia\n",
    "- Utilizar `bagging_het` del archivo `util_bagging.py`\n",
    "- Reportar métricas finales en test\n",
    "\n",
    "### 5. **Random Forest Básico**\n",
    "- Usar `n_estimators = 45`\n",
    "- Evaluar OOB accuracy\n",
    "- Identificar 4 características más importantes\n",
    "- Evaluar desempeño en test\n",
    "\n",
    "### 6. **Random Forest con Grid Search**\n",
    "- Hiperparámetros a buscar:\n",
    "  - `n_estimators`: 50 a 200 (paso de 10, total 15 valores)\n",
    "  - `max_features`: [`sqrt`, `log2`, `None`]\n",
    "- Reportar:\n",
    "  - Mejores hiperparámetros\n",
    "  - OOB accuracy\n",
    "  - Importancia de atributos\n",
    "  - Análisis de métricas, curva ROC y AUC\n",
    "\n",
    "### 7. **Clientes con Mayor Riesgo de Renuncia**\n",
    "- Con el modelo final optimizado de Random Forest:\n",
    "  - Identificar y mostrar los **15 clientes con mayor probabilidad de renunciar**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAisOYgo9vx3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IMPMKZm693cn",
    "outputId": "fe7d5c6d-1262-4c28-e9dd-7dbbc713cdf8"
   },
   "outputs": [],
   "source": [
    "# Exploración de Datos: telecom_churn.csv\n",
    "\n",
    "# Carga del dataset\n",
    "df = pd.read_csv(\"telecom_churn.csv\")\n",
    "\n",
    "# Información general del dataset\n",
    "print(\"Información general del dataset:\")\n",
    "df.info()\n",
    "\n",
    "# Muestra aleatoria de registros\n",
    "print(\"\\nMuestra aleatoria de registros:\")\n",
    "display(df.sample(5, random_state=42))\n",
    "\n",
    "# Revisión de duplicados\n",
    "dup_count = df.duplicated().sum()\n",
    "print(f\"\\nDuplicados detectados: {dup_count}\")\n",
    "if dup_count > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"Duplicados eliminados. Total de registros: {df.shape[0]}\")\n",
    "\n",
    "# Estadísticas descriptivas de variables numéricas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "display(df.describe().T)\n",
    "\n",
    "# Revisión de valores nulos\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Distribución de la variable objetivo\n",
    "print(\"\\nDistribución de la variable 'Churn':\")\n",
    "print(df['Churn'].value_counts())\n",
    "\n",
    "print(\"\\nDistribución relativa de 'Churn':\")\n",
    "print(df['Churn'].value_counts(normalize=True).round(3))\n",
    "\n",
    "# Visualización de la variable objetivo\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Churn', data=df, palette='pastel')\n",
    "plt.title(\"Distribución de la variable objetivo 'Churn'\")\n",
    "plt.xlabel(\"Churn (0 = No renuncia, 1 = Renuncia)\")\n",
    "plt.ylabel(\"Cantidad de clientes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRO8bgUz-OEn"
   },
   "source": [
    "## Análisis Crítico Basado en Datos\n",
    "\n",
    "### Desbalance en la variable objetivo (`Churn`)\n",
    "El 14,5% de los clientes en el dataset corresponde a casos de renuncia (`Churn = 1`), mientras que el 85,5% permanece. Este desbalance severo invalida el uso exclusivo de métricas como `accuracy`, ya que un modelo que prediga siempre la clase mayoritaria alcanzaría un 85% de precisión sin aprender nada útil. Por tanto, se utilizarán métricas más adecuadas como `recall`, `f1-score` y curvas `ROC/AUC`, que penalizan los errores sobre la clase minoritaria.\n",
    "\n",
    "Además, las visualizaciones de variables predictoras deben desagregarse por clase (`Churn = 0` y `Churn = 1`) para evitar que los promedios oculten diferencias relevantes.\n",
    "\n",
    "### Variables con fuerte sesgo y concentración en ceros\n",
    "- `DataUsage`: El 50% de los clientes tiene un uso mensual de datos igual a 0 GB, mientras que algunos alcanzan hasta 5.4 GB. Esto sugiere una distribución altamente asimétrica. Además, su valor depende directamente de si el cliente tiene `DataPlan`.\n",
    "- `ContractRenewal`: El 90% de los clientes renovó contrato recientemente (`valor = 1`), lo que indica una variable muy desequilibrada pero potencialmente predictiva.\n",
    "- `DataPlan`: Solo el 28% de los clientes tiene plan de datos (`valor = 1`). Dado que `DataUsage = 0` cuando no hay plan, estas dos variables están estructuralmente ligadas y se evaluará su tratamiento conjunto.\n",
    "- `CustServCalls`: Aunque su valor máximo es 9, la mayoría de los clientes realiza entre 0 y 2 llamadas al servicio al cliente. La variable es fuertemente sesgada y puede estar asociada al nivel de insatisfacción del cliente.\n",
    "\n",
    "### Potenciales outliers en variables continuas\n",
    "- `DayMins`: Varía desde 0 hasta 350.8 minutos, con una mediana de 179.4. Los valores extremos podrían representar clientes inactivos o altamente intensivos, y deben analizarse con más detalle.\n",
    "- `MonthlyCharge`: Fluctúa entre 14.0 y 111.3 USD, con una media de 56.3. Tiene alta probabilidad de correlación con `DayMins` y `OverageFee`, por lo que se evaluará su redundancia o complementariedad con otras variables relacionadas al costo.\n",
    "\n",
    "Estas observaciones guían las decisiones de preprocesamiento, selección de métricas y estrategias de modelado que se adoptarán en las siguientes etapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iYMpem1c-V82",
    "outputId": "1926ea04-0d12-40d1-ffee-d764c022c70b"
   },
   "outputs": [],
   "source": [
    "# Exploración visual avanzada\n",
    "\n",
    "# Configuración de estilo visual\n",
    "sns.set_theme(context=\"notebook\",\n",
    "              style=\"whitegrid\",\n",
    "              palette=\"Set2\",\n",
    "              font_scale=1.1)\n",
    "\n",
    "# Pair Plot con variables seleccionadas\n",
    "pair_vars = ['AccountWeeks', 'DataUsage',\n",
    "             'DayMins', 'MonthlyCharge',\n",
    "             'CustServCalls', 'Churn']\n",
    "\n",
    "sns.pairplot(df[pair_vars],\n",
    "             hue=\"Churn\",\n",
    "             diag_kind=\"kde\",\n",
    "             corner=True,\n",
    "             palette=\"Set2\",\n",
    "             plot_kws=dict(alpha=0.5, linewidth=0),\n",
    "             height=2.2)\n",
    "plt.suptitle(\"Distribución conjunta de variables por clase (Churn)\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Boxplots 3×3 por clase Churn\n",
    "box_vars = ['AccountWeeks', 'DataUsage', 'DayMins',\n",
    "            'MonthlyCharge', 'OverageFee', 'RoamMins',\n",
    "            'CustServCalls', 'DayCalls', 'ContractRenewal']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10), sharey=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, col in zip(axes, box_vars):\n",
    "    sns.boxplot(x=\"Churn\",\n",
    "                y=col,\n",
    "                data=df,\n",
    "                ax=ax,\n",
    "                palette=[\"#4c72b0\", \"#dd8452\"],\n",
    "                hue_order=[0, 1])\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Distribuciones por clase: Boxplots agrupados por Churn\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Heatmap de correlaciones numéricas\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df.corr(numeric_only=True)\n",
    "sns.heatmap(corr,\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            cmap=\"crest\",\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": .7})\n",
    "plt.title(\"Matriz de correlación entre variables numéricas\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análisis de churn según llamadas a soporte\n",
    "df['CSCalls_bin'] = pd.cut(df['CustServCalls'],\n",
    "                           bins=[-0.1, 1, 3, 5, 9],\n",
    "                           labels=['0-1', '2-3', '4-5', '6-9'])\n",
    "\n",
    "churn_rate = (\n",
    "    df.groupby('CSCalls_bin')['Churn']\n",
    "      .mean()\n",
    "      .reset_index()\n",
    "      .rename(columns={'Churn': 'Churn_Rate'})\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=churn_rate,\n",
    "            x='CSCalls_bin',\n",
    "            y='Churn_Rate',\n",
    "            palette=\"Blues\",\n",
    "            edgecolor=\"black\")\n",
    "\n",
    "plt.axhline(df['Churn'].mean(), ls='--', color='gray', label='Tasa global')\n",
    "plt.ylabel(\"Tasa de Churn\")\n",
    "plt.xlabel(\"Llamadas a Soporte (agrupadas)\")\n",
    "plt.title(\"Relación entre llamadas a soporte y probabilidad de renuncia\")\n",
    "plt.ylim(0, churn_rate['Churn_Rate'].max()*1.1)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4UKUgTs-hcp"
   },
   "source": [
    "## Evaluación de Visualizaciones Exploratorias\n",
    "\n",
    "### 1. Pair Plot – Variables seleccionadas vs Churn\n",
    "\n",
    "**Interpretación:**\n",
    "\n",
    "- `DayMins` y `MonthlyCharge` presentan una relación positiva clara: a mayor uso, mayor cargo. Sin embargo, los casos de `Churn = 1` tienden a concentrarse en valores altos de `DayMins`, con alta dispersión en `MonthlyCharge`, lo que sugiere percepción de sobrecosto en algunos clientes intensivos.\n",
    "- `CustServCalls` muestra patrones verticales (variable discreta), y a partir de 4 llamadas se observa una clara concentración de clientes que renuncian.\n",
    "- `DataUsage` presenta una distribución mayormente baja o nula. Los valores altos no diferencian con claridad entre clases, lo que limita su utilidad discriminante, especialmente considerando su dependencia estructural con `DataPlan`.\n",
    "\n",
    "**Evaluación:**\n",
    "\n",
    "- Útil para detectar tendencias generales, aunque algunos pares de variables no muestran separación clara entre clases.\n",
    "- La dispersión y no linealidad observada refuerzan la idea de utilizar modelos no lineales (como árboles o SVM con kernel) para capturar relaciones complejas.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Boxplots 3x3 por clase (`Churn`)\n",
    "\n",
    "**Hallazgos relevantes:**\n",
    "\n",
    "- `DayMins` y `MonthlyCharge` son más altos en promedio para quienes renuncian, lo que puede relacionarse con la percepción de tarifas elevadas.\n",
    "- `CustServCalls` está fuertemente sesgada a la derecha para `Churn = 1`, con varios clientes que han realizado entre 4 y 9 llamadas. Esto sugiere un vínculo fuerte entre frustración del cliente y renuncia.\n",
    "- `ContractRenewal` se comporta como un indicador binario muy claro: casi todos los que renuncian no renovaron contrato recientemente.\n",
    "- `DataUsage` sigue mostrando baja variabilidad y poco poder de discriminación, con predominancia de valores bajos en ambas clases.\n",
    "\n",
    "**Evaluación:**\n",
    "\n",
    "- Excelente herramienta para analizar la distribución por clase.\n",
    "- Útil tanto para la construcción de modelos explicativos como para comunicación ejecutiva de hallazgos.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Heatmap de correlaciones\n",
    "\n",
    "**Puntos clave:**\n",
    "\n",
    "- `Churn` muestra correlación negativa moderada con `ContractRenewal` (-0.26), lo que respalda su valor como predictor clave.\n",
    "- Correlaciones positivas más débiles se observan con `DayMins` y `CustServCalls` (≈ +0.20).\n",
    "- Fuerte colinealidad entre `DataPlan` y `DataUsage` (≈ +0.95), y también entre `DayMins`, `MonthlyCharge` y `OverageFee`, lo que indica la posibilidad de redundancia en estas dimensiones de costo/uso.\n",
    "\n",
    "**Evaluación:**\n",
    "\n",
    "- No se detectan correlaciones extremas entre predictores (mayores a ±0.95, excepto las ya explicadas), por lo que no se eliminarán variables de forma automática. Se priorizará la evaluación de importancia durante el modelado.\n",
    "- El bajo nivel de correlación lineal con `Churn` sugiere que los modelos lineales simples tendrán dificultad para separar clases, reforzando la elección de modelos no lineales como Random Forest o SVM.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Barplot – Tasa de `Churn` por tramos de `CustServCalls`\n",
    "\n",
    "**Observaciones clave:**\n",
    "\n",
    "- Tasa de churn inferior al 13% para clientes con 0 a 3 llamadas al servicio al cliente.\n",
    "- La tasa se eleva al 50% para quienes han realizado entre 4 y 5 llamadas.\n",
    "- Supera el 60% para el grupo con 6 a 9 llamadas.\n",
    "\n",
    "**Conclusión de negocio:**\n",
    "\n",
    "- El número de contactos con soporte es un indicador directo de riesgo de renuncia.\n",
    "- Umbral crítico: **más de 3 llamadas a soporte multiplica por 5 la probabilidad de churn**.\n",
    "- Esta variable es altamente accionable para diseñar alertas tempranas o programas proactivos de retención.\n",
    "\n",
    "**Evaluación:**\n",
    "\n",
    "- La visualización más útil desde una perspectiva táctica.\n",
    "- Comunica de forma clara y efectiva un umbral de riesgo operacional.\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusión general del análisis visual:**\n",
    "\n",
    "Estas visualizaciones permiten identificar variables predictoras relevantes (`ContractRenewal`, `CustServCalls`, `AccountWeeks`, `DayMins`, `MonthlyCharge`), detectar relaciones no lineales que justifican el uso de modelos más robustos, y aportar argumentos concretos para futuras decisiones de ingeniería de variables y estrategia de modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "id": "Ad-hIB0v-pnq",
    "outputId": "ebdf6bb8-c01f-4bf1-94ce-b33c4f4fe006"
   },
   "outputs": [],
   "source": [
    "# Árbol de Decisión – Modelo Base\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    classification_report, f1_score,\n",
    "    recall_score, precision_score\n",
    ")\n",
    "\n",
    "# Eliminamos variable categórica que no sirve para el modelo base\n",
    "df_model = df.drop(columns='CSCalls_bin', errors='ignore')\n",
    "\n",
    "# Separación de variables predictoras y objetivo\n",
    "X = df_model.drop(columns='Churn')\n",
    "y = df_model['Churn']\n",
    "\n",
    "# División del dataset con estratificación por clase\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Entrenamiento del árbol de decisión base (sin ajuste de hiperparámetros)\n",
    "tree_base = DecisionTreeClassifier(random_state=42)\n",
    "tree_base.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones sobre el set de test\n",
    "y_pred_base = tree_base.predict(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred_base)\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# Visualización de matriz de confusión\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Churn\", \"Churn\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matriz de Confusión – Árbol de Decisión Base\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificación completo\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred_base, target_names=[\"No Churn\", \"Churn\"]))\n",
    "\n",
    "# Accuracy general\n",
    "print(\"Accuracy (Train):\", round(tree_base.score(X_train, y_train), 4))\n",
    "print(\"Accuracy (Test):\", round(tree_base.score(X_test, y_test), 4))\n",
    "\n",
    "# Métricas específicas para la clase minoritaria (Churn = 1)\n",
    "print(\"\\nMétricas específicas – Clase Churn = 1\")\n",
    "print(\"F1-score   :\", round(f1_score(y_test, y_pred_base, pos_label=1), 4))\n",
    "print(\"Recall     :\", round(recall_score(y_test, y_pred_base, pos_label=1), 4))\n",
    "print(\"Precision  :\", round(precision_score(y_test, y_pred_base, pos_label=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYR6NW2G-jQ9"
   },
   "source": [
    "### Conclusión – Árbol de Decisión Base\n",
    "\n",
    "El modelo base alcanza un buen accuracy general (89,2%), pero presenta **sobreajuste severo** (100% en entrenamiento) y **recall limitado para la clase minoritaria** (`Churn = 1`, con 58,8%). Esto confirma que el árbol está memorizando patrones sin generalizar correctamente. Se requiere ajustar su complejidad para mejorar la capacidad de predicción sobre los clientes que efectivamente renuncian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "id": "AkNkLcXN-oa9",
    "outputId": "df7ce26f-75d8-4244-a1f1-157ca0411d22"
   },
   "outputs": [],
   "source": [
    "# Árbol de Decisión – Optimización con GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Hiperparámetros a buscar\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, 25],\n",
    "    'min_samples_split': [0.01, 0.02, 0.03, 0.04]\n",
    "}\n",
    "\n",
    "# Modelo base\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Búsqueda por grilla con 5-fold CV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=tree,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',  # enfocado en clase minoritaria\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo\n",
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nMejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Evaluación del modelo optimizado\n",
    "y_pred_opt = best_tree.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred_opt)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Churn\", \"Churn\"])\n",
    "disp.plot(cmap=\"YlGnBu\")\n",
    "plt.title(\"Matriz de Confusión – Árbol Optimizado\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Reporte de métricas\n",
    "print(\"\\nReporte de Clasificación – Árbol Optimizado:\")\n",
    "print(classification_report(y_test, y_pred_opt, target_names=[\"No Churn\", \"Churn\"]))\n",
    "\n",
    "# Comparación de accuracy\n",
    "print(\"Accuracy (Train):\", round(best_tree.score(X_train, y_train), 4))\n",
    "print(\"Accuracy (Test):\", round(best_tree.score(X_test, y_test), 4))\n",
    "\n",
    "# Métricas específicas (Churn = 1)\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "print(\"\\nMétricas – Clase Churn = 1 (Modelo Optimizado)\")\n",
    "print(\"F1-score   :\", round(f1_score(y_test, y_pred_opt), 4))\n",
    "print(\"Recall     :\", round(recall_score(y_test, y_pred_opt), 4))\n",
    "print(\"Precision  :\", round(precision_score(y_test, y_pred_opt), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJdifeO3_AuQ"
   },
   "source": [
    "### Conclusión – Árbol de Decisión Optimizado\n",
    "\n",
    "La optimización del árbol con `GridSearchCV` logró reducir significativamente el **sobreajuste** (accuracy de entrenamiento bajó de 1.0 a 0.94), sin comprometer el rendimiento en test. La precisión para detectar clientes que renuncian (`Churn = 1`) mejoró de 64% a 68%, lo que indica una menor tasa de falsos positivos. Aunque el **recall bajó levemente** (de 58,8% a 55,7%), el modelo es ahora más conservador, prediciendo menos casos de churn, pero con mayor certeza.\n",
    "\n",
    "En resumen, el árbol optimizado entrega **mejor balance entre precisión y generalización**, y es una base sólida antes de aplicar técnicas más robustas como Bagging o Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-mSJq5c_CVX"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 946
    },
    "id": "xGdZIavx_Fno",
    "outputId": "689a371d-abe2-4987-f6df-c78192550176"
   },
   "outputs": [],
   "source": [
    "# Bagging Homogéneo con SMOTE – 200 Árboles\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    accuracy_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "\n",
    "# 3.a Balanceo del conjunto de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Distribución tras SMOTE (entrenamiento balanceado):\")\n",
    "print(pd.Series(y_train_res).value_counts())\n",
    "\n",
    "# 3.b Entrenamiento del modelo Bagging homogéneo\n",
    "bagging_tree_200 = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    n_estimators=200,\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "bagging_tree_200.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 3.c Evaluación en test\n",
    "y_pred_bag = bagging_tree_200.predict(X_test)\n",
    "\n",
    "# Matriz de Confusión\n",
    "cm = confusion_matrix(y_test, y_pred_bag)\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Churn\", \"Churn\"])\n",
    "disp.plot(cmap=\"YlOrRd\")\n",
    "plt.title(\"Matriz de Confusión – Bagging Homogéneo\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Reporte completo\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred_bag, target_names=[\"No Churn\", \"Churn\"]))\n",
    "\n",
    "# Métricas específicas\n",
    "acc_train = bagging_tree_200.score(X_train_res, y_train_res)\n",
    "acc_test = accuracy_score(y_test, y_pred_bag)\n",
    "f1 = f1_score(y_test, y_pred_bag)\n",
    "rec = recall_score(y_test, y_pred_bag)\n",
    "prec = precision_score(y_test, y_pred_bag)\n",
    "\n",
    "print(\"\\nResumen de métricas:\")\n",
    "print(f\"Accuracy (Train): {acc_train:.4f}\")\n",
    "print(f\"Accuracy (Test) : {acc_test:.4f}\")\n",
    "print(f\"F1-score (Churn = 1): {f1:.4f}\")\n",
    "print(f\"Recall    (Churn = 1): {rec:.4f}\")\n",
    "print(f\"Precision (Churn = 1): {prec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5QUXbc1_OuR"
   },
   "source": [
    "## Interpretación — Bagging + SMOTE (200 árboles)\n",
    "\n",
    "### Puntos positivos\n",
    "\n",
    "- **Balance perfecto 1:1 tras SMOTE**  se elimina el sesgo de entrada para el modelo.\n",
    "- **Recall de Churn mejora de 0.56 a 0.70**  \n",
    "  → Ahora detecta 7 de cada 10 desertores (29 FN en lugar de 40).\n",
    "- Responde a la **prioridad del negocio**: minimizar falsos negativos.\n",
    "- **Varianza reducida**: el ensamble de 200 árboles suaviza la sobre-adaptación típica de un árbol único.\n",
    "- **F1 global para Churn se mantiene en 0.61**, pese a la caída de precisión  la ganancia en recall lo compensa.\n",
    "\n",
    "### Puntos débiles\n",
    "\n",
    "- **Precisión para Churn baja a 0.54**  \n",
    "  → Casi la mitad de los clientes marcados como desertores **no lo son** (57 falsos positivos).\n",
    "- **Accuracy global cae** de 0.898 a 0.870  esperable al priorizar recall.\n",
    "- **Macro-F1 (0.77)** no mejora respecto al árbol optimizado (0.78) el avance se concentra exclusivamente en **recall**.\n",
    "- **Sin ajuste de hiperparámetros** (ni profundidad ni features por árbol)  aún hay margen para **optimización fina**.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "El modelo de **Bagging con SMOTE** cumple su **objetivo principal**:  \n",
    "**elevar la sensibilidad hacia la clase minoritaria (Churn)**, alcanzando un **recall del 70 %**, a costa de **reducción en precisión** y **accuracy global**.\n",
    "\n",
    "### Comparación de Métricas Clave\n",
    "\n",
    "| Métrica              | Árbol Optimizado | Bagging + SMOTE | Cambio     |\n",
    "|----------------------|------------------|------------------|------------|\n",
    "| Recall (Churn)       | 0.56             | 0.70             | ↑ 0.14     |\n",
    "| Precision (Churn)    | 0.68             | 0.54             | ↓ 0.14     |\n",
    "| F1-score (Churn)     | 0.61             | 0.61             | ≈          |\n",
    "| Accuracy (global)    | 0.898            | 0.870            | ↓ 0.028    |\n",
    "\n",
    "---\n",
    "\n",
    "## Decisión de Negocio\n",
    "\n",
    "Si el **costo de perder un cliente desertor supera con creces** el de **contactar erróneamente a un cliente fiel**,  \n",
    "este modelo es **claramente preferible** al árbol individual optimizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 928
    },
    "id": "TV_fUXoH_Xfb",
    "outputId": "02e0a2b8-32e5-488c-af3b-5153116d48cf"
   },
   "outputs": [],
   "source": [
    "# Bagging Heterogéneo\n",
    "%run util_bagging.py\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from util_bagging import bagging_het\n",
    "\n",
    "# 4.a Definir modelos base (misma semilla para reproducibilidad)\n",
    "clf_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf_dt = DecisionTreeClassifier(random_state=42)\n",
    "clf_svc_rbf = SVC(kernel='rbf', probability=False, random_state=42)\n",
    "clf_svc_sig = SVC(kernel='sigmoid', probability=False, random_state=42)\n",
    "\n",
    "# Lista de clasificadores inicial\n",
    "estimadores = [clf_lr, clf_dt, clf_svc_rbf, clf_svc_sig]\n",
    "\n",
    "# 4.b Evaluación previa de cada estimador individual en entrenamiento (F1-score)\n",
    "print(\"F1-score de cada modelo sobre el conjunto de entrenamiento:\")\n",
    "for i, clf in enumerate(estimadores):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    f1 = f1_score(y_train, y_pred_train)\n",
    "    print(f\"Modelo {i} ({clf.__class__.__name__}): F1-score = {f1:.4f}\")\n",
    "\n",
    "# 4.c Repetir el mejor modelo según F1 (en este caso DecisionTree suele ganar)\n",
    "# Vamos a repetir el mejor modelo una vez más en la lista\n",
    "estimadores = [clf_lr, clf_dt, clf_dt, clf_svc_rbf, clf_svc_sig]  # Árbol duplicado\n",
    "\n",
    "# 4.d Ejecutar bagging heterogéneo\n",
    "T = 200\n",
    "modelos_entrenados, yhat_matrix, yhat_final, oob_idx = bagging_het(X_train, y_train, T, estimadores, X_test)\n",
    "\n",
    "# 4.e Evaluación final\n",
    "y_test_pred = yhat_final.astype(int)\n",
    "\n",
    "print(\"\\nMatriz de Confusión – Bagging Heterogéneo:\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Churn\", \"Churn\"])\n",
    "disp.plot(cmap=\"YlGnBu\")\n",
    "plt.title(\"Matriz de Confusión – Bagging Heterogéneo\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=[\"No Churn\", \"Churn\"]))\n",
    "\n",
    "# Métricas específicas para Churn = 1\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "rec = recall_score(y_test, y_test_pred)\n",
    "prec = precision_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nMétricas – Clase Churn = 1\")\n",
    "print(f\"F1-score   : {f1:.4f}\")\n",
    "print(f\"Recall     : {rec:.4f}\")\n",
    "print(f\"Precision  : {prec:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "C5RmlWBU_isP",
    "outputId": "d3ff7bdc-920f-4b98-e87a-6902976badac"
   },
   "outputs": [],
   "source": [
    "# Bagging Heterogéneo – Versión calibrada (árbol dominante)\n",
    "\n",
    "# Lista de clasificadores con peso aumentado para el árbol\n",
    "estimadores_calibrados = [clf_dt]*5 + [clf_lr, clf_svc_rbf, clf_svc_sig]\n",
    "\n",
    "# Reentrenar bagging heterogéneo\n",
    "T = 200\n",
    "modelos_calibrados, yhat_matrix_cal, yhat_final_cal, oob_idx_cal = bagging_het(\n",
    "    X_train, y_train, T, estimadores_calibrados, X_test\n",
    ")\n",
    "\n",
    "# Predicción final\n",
    "y_pred_cal = yhat_final_cal.astype(int)\n",
    "\n",
    "# Evaluación\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, f1_score, recall_score, precision_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_cal)\n",
    "print(\"Matriz de Confusión – Bagging Heterogéneo (calibrado):\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Churn\", \"Churn\"])\n",
    "disp.plot(cmap=\"YlGnBu\")\n",
    "plt.title(\"Matriz de Confusión – Bagging Heterogéneo (Árbol Reforzado)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred_cal, target_names=[\"No Churn\", \"Churn\"]))\n",
    "\n",
    "# Métricas específicas\n",
    "f1 = f1_score(y_test, y_pred_cal)\n",
    "rec = recall_score(y_test, y_pred_cal)\n",
    "prec = precision_score(y_test, y_pred_cal)\n",
    "\n",
    "print(\"\\nMétricas – Clase Churn = 1 (modelo calibrado)\")\n",
    "print(f\"F1-score   : {f1:.4f}\")\n",
    "print(f\"Recall     : {rec:.4f}\")\n",
    "print(f\"Precision  : {prec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plb8Li9d_n4k"
   },
   "source": [
    "### Conclusión – Bagging Heterogéneo Calibrado\n",
    "\n",
    "Luego de reforzar la influencia del mejor modelo individual (Árbol de Decisión) en la lista de clasificadores heterogéneos, el ensamble logró un rendimiento significativamente superior. El **F1-score sobre la clase `Churn = 1` aumentó de 0.25 a 0.64**, y el modelo ahora captura el 49,5% de los clientes que efectivamente renuncian, con una **precisión alta (89%)**.\n",
    "\n",
    "Este resultado demuestra que en ensambles heterogéneos **no todos los modelos deben pesar lo mismo**: dar más peso a los modelos competentes permite corregir el efecto negativo de clasificadores débiles, mejorando el balance entre cobertura y exactitud en la clase objetivo.\n",
    "\n",
    "El Bagging Heterogéneo calibrado se posiciona como un modelo intermedio robusto, útil en escenarios donde se requiere confiabilidad sin sacrificar demasiada sensibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "liDnsjq7_sHN",
    "outputId": "53ac252d-c602-4967-ea8d-349667d8256d"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, recall_score, precision_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Entrenamiento del modelo Random Forest con OOB\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=45,\n",
    "    oob_score=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# OOB Score\n",
    "print(f\"OOB Accuracy (entrenamiento): {rf_model.oob_score_:.4f}\")\n",
    "\n",
    "# Accuracy en test\n",
    "acc_test_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy (Test): {acc_test_rf:.4f}\")\n",
    "\n",
    "# Reporte general\n",
    "print(\"\\nReporte de Clasificación – Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=[\"No Churn\", \"Churn\"]))\n",
    "\n",
    "# Matriz de Confusión\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Churn\", \"Churn\"])\n",
    "disp.plot(cmap=\"PuBu\")\n",
    "plt.title(\"Matriz de Confusión – Random Forest (n=45)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Métricas específicas (Churn = 1)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "rec_rf = recall_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nMétricas – Clase Churn = 1 (Random Forest)\")\n",
    "print(f\"F1-score   : {f1_rf:.4f}\")\n",
    "print(f\"Recall     : {rec_rf:.4f}\")\n",
    "print(f\"Precision  : {prec_rf:.4f}\")\n",
    "\n",
    "# Importancia de variables\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "feat_imp = pd.DataFrame({\n",
    "    \"feature\": X_train.columns,\n",
    "    \"importance\": rf_model.feature_importances_\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "# Mostrar las 4 más importantes\n",
    "print(\"\\nTop 4 variables más importantes:\")\n",
    "print(feat_imp.head(4))\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=feat_imp.head(10), x=\"importance\", y=\"feature\", palette=\"viridis\")\n",
    "plt.title(\"Importancia de variables – Random Forest (Top 10)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xZYXoxk_y0z"
   },
   "source": [
    "## Conclusión – Random Forest (n=45)\n",
    "\n",
    "El modelo Random Forest con `n_estimators=45` y validación *out-of-bag* (OOB) logra el mejor rendimiento general hasta ahora, con excelente equilibrio entre precisión, sensibilidad y capacidad de generalización.\n",
    "\n",
    "### Rendimiento:\n",
    "- **Accuracy (Test):** 92.8 %\n",
    "- **OOB Score (Train):** 93.2 %\n",
    "- **F1-score (Churn = 1):** 0.721\n",
    "- **Recall (Churn = 1):** 0.639\n",
    "- **Precision (Churn = 1):** 0.827\n",
    "\n",
    "Este modelo mejora significativamente la detección de clientes que efectivamente renuncian (`churn = 1`), sin sacrificar precisión. Su capacidad de generalización queda respaldada por la validación OOB.\n",
    "\n",
    "### Variables más importantes:\n",
    "1. `DayMins` – 19.6 %\n",
    "2. `MonthlyCharge` – 16.3 %\n",
    "3. `CustServCalls` – 14.1 %\n",
    "4. `DataUsage` – 9.5 %\n",
    "\n",
    "Estas variables revelan un patrón claro: **los clientes que más usan el servicio y llaman al soporte tienen mayor probabilidad de abandonar**.\n",
    "\n",
    "### Evaluación Final:\n",
    "Random Forest supera al árbol de decisión base, al árbol optimizado, al bagging clásico e incluso al bagging heterogéneo calibrado. No requiere balanceo explícito y mantiene buena interpretabilidad. Es el **mejor modelo candidato** para un primer sistema de alerta de churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LwEta1HO_534",
    "outputId": "120f9b2b-750e-4454-ff2b-149a78d4b6c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Definir modelo base\n",
    "rf = RandomForestClassifier(\n",
    "    oob_score=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Definir la grilla de hiperparámetros\n",
    "param_grid = {\n",
    "    \"n_estimators\": list(range(50, 201, 10)),\n",
    "    \"max_features\": ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Búsqueda de hiperparámetros con validación cruzada\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Resultados de búsqueda\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_rf.best_params_)\n",
    "\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "print(\"OOB Accuracy (entrenamiento):\", round(best_rf.oob_score_, 4))\n",
    "\n",
    "# Evaluación en conjunto de test\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_prob_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_rf, X_test, y_test, display_labels=[\"No Churn\", \"Churn\"]\n",
    ")\n",
    "plt.title(\"Matriz de Confusión – Random Forest (Ajustado)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=[\"No Churn\", \"Churn\"]))\n",
    "\n",
    "# Curva ROC y AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob_rf)\n",
    "auc = roc_auc_score(y_test, y_prob_rf)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.4f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.title(\"Curva ROC – Random Forest (Ajustado)\")\n",
    "plt.xlabel(\"Tasa de Falsos Positivos (FPR)\")\n",
    "plt.ylabel(\"Tasa de Verdaderos Positivos (TPR)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Importancia de variables\n",
    "feat_importance = pd.DataFrame({\n",
    "    \"feature\": X_train.columns,\n",
    "    \"importance\": best_rf.feature_importances_\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"Top 4 variables más importantes:\")\n",
    "print(feat_importance.head(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pw3QFc_j_5B1"
   },
   "source": [
    "## 6. Conclusión – Random Forest Optimizado (GridSearch)\n",
    "\n",
    "El modelo Random Forest ajustado con búsqueda en grilla muestra un desempeño robusto en la detección de clientes con alta probabilidad de renuncia (`Churn = 1`).\n",
    "\n",
    "**Mejores hiperparámetros encontrados:**\n",
    "- `n_estimators = 200`\n",
    "- `max_features = 'sqrt'`\n",
    "\n",
    "**Desempeño del modelo:**\n",
    "- **OOB Accuracy (entrenamiento):** 0.9366\n",
    "- **Accuracy (test):** 0.9280\n",
    "- **AUC (ROC):** 0.8582\n",
    "\n",
    "**Métricas para clase `Churn = 1` (clientes que renuncian):**\n",
    "- `Precision`: 0.83\n",
    "- `Recall`: 0.64\n",
    "- `F1-score`: 0.72\n",
    "\n",
    "**Top 4 variables más importantes:**\n",
    "- `DayMins`: 0.2008\n",
    "- `MonthlyCharge`: 0.1659\n",
    "- `CustServCalls`: 0.1462\n",
    "- `OverageFee`: 0.0945\n",
    "\n",
    "Estas variables tienen sentido desde el punto de vista del negocio, ya que reflejan consumo elevado, fricción con el servicio (soporte) y cobros extras inesperados, todos factores que pueden aumentar la propensión a renunciar.\n",
    "\n",
    "**Conclusión:**  \n",
    "El modelo Random Forest optimizado logra un equilibrio sólido entre capacidad predictiva y generalización, con una mejora relevante sobre el modelo base. Las variables más importantes tienen interpretación clara y directa, lo que lo hace útil para acciones preventivas de retención."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "lfRFu_gYAF0J",
    "outputId": "b677a72b-aeaf-41df-9dba-999c0cc8b583"
   },
   "outputs": [],
   "source": [
    "# Predicción de probabilidades de churn\n",
    "y_scores = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Crear DataFrame con probabilidades y datos originales\n",
    "df_test_scores = X_test.copy()\n",
    "df_test_scores['Churn_Prob'] = y_scores\n",
    "df_test_scores['Churn_Real'] = y_test.values\n",
    "\n",
    "# Ordenar por mayor probabilidad de churn\n",
    "top_15 = df_test_scores.sort_values(by=\"Churn_Prob\", ascending=False).head(15)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Top 15 clientes con mayor propensión a renunciar:\")\n",
    "display(top_15[['Churn_Prob', 'Churn_Real'] + list(X_test.columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcLVlRytAPVe"
   },
   "source": [
    "## Análisis de los 15 clientes con mayor propensión a renunciar\n",
    "\n",
    "El modelo Random Forest optimizado identificó a los siguientes 15 clientes del conjunto de test como los más propensos a renunciar (probabilidad de `Churn` superior al 93%).\n",
    "\n",
    "### Variables clave observadas en estos clientes\n",
    "\n",
    "**1. DataPlan = 0 (ausencia de plan de datos):**  \n",
    "Todos los clientes del Top 15 carecen de un plan de datos. Esto puede generar frustración en usuarios intensivos en minutos o que requieren conexión constante, siendo una señal crítica de desajuste entre oferta y necesidad.\n",
    "\n",
    "**2. Uso intensivo de minutos diurnos (`DayMins`):**  \n",
    "Muchos casos presentan consumos muy altos, superando los **270 minutos diarios**. Este patrón sugiere clientes muy activos o dependientes del servicio, lo cual debería asociarse a retención, pero también puede llevar a sobrecargos no deseados si no se ajusta el plan.\n",
    "\n",
    "**3. Tarifas elevadas (`MonthlyCharge` y `OverageFee`):**  \n",
    "Más del 60% de los casos tienen **cargos mensuales altos (sobre $70)** y **sobrecargos (`OverageFee`) sobre los $10**, lo que puede estar afectando la percepción de valor del servicio.\n",
    "\n",
    "**4. Contactos con servicio al cliente (`CustServCalls`):**  \n",
    "Cerca del 50% de los clientes realizaron múltiples llamados al servicio (4 o más). Esto indica posibles problemas no resueltos, lo que unido al uso intensivo y a la falta de plan de datos podría haber gatillado su decisión de renunciar.\n",
    "\n",
    "**5. Variables contextuales secundarias:**  \n",
    "- `RoamMins`: Algunos clientes con altos minutos de roaming (sobre 10 minutos), lo cual podría generar cargos adicionales.\n",
    "- `AccountWeeks`: La mayoría son clientes antiguos (más de 90 semanas), lo que sugiere que **no se está premiando la lealtad**, o que **el desgaste supera los beneficios percibidos**.\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "Los 15 casos con mayor probabilidad de churn muestran un **patrón consistente de clientes sin plan de datos, con uso intensivo y cobros altos**, varios de los cuales han interactuado con servicio al cliente, posiblemente sin resolución efectiva.  \n",
    "\n",
    "**Recomendaciones estratégicas:**\n",
    "- **Segmentación proactiva** de clientes sin plan de datos con alto uso.\n",
    "- Ofertas personalizadas de planes adecuados con tarifas predecibles.\n",
    "- Intervenciones directas sobre clientes que contactan repetidamente a soporte.\n",
    "- Programa de retención enfocado en clientes antiguos con altos cargos.\n",
    "\n",
    "Este análisis permite anticiparse a pérdidas de clientes valiosos y rediseñar políticas comerciales o de soporte para mejorar la retención."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ca909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Exportadores: gráficos y tablas ===\n",
    "try:\n",
    "    # Pairplot (requiere df y lista de columnas)\n",
    "    cols_pairplot  = []  # rellena con columnas numéricas de interés\n",
    "    if 'df' in globals() and len(cols_pairplot) > 0 and TARGET in df.columns:\n",
    "        pp = sns.pairplot(df[cols_pairplot + [TARGET]].copy(), hue=TARGET, corner=True,\n",
    "                          plot_kws=dict(alpha=0.6, s=20, edgecolor=\"none\"))\n",
    "        pp.fig.suptitle(\"Pair Plot – Variables seleccionadas vs Churn\", y=1.02)\n",
    "        safe_savefig(pp.fig, FIG_DIR / \"pairplot_vs_churn.png\")\n",
    "        plt.close('all')\n",
    "    else:\n",
    "        print('[INFO] Pairplot omitido: define cols_pairplot y asegúrate de tener df y TARGET.')\n",
    "\n",
    "    # Boxplots 3x3 (hasta 9 columnas numericas)\n",
    "    cols_box = []  # rellena con hasta 9 columnas\n",
    "    if 'df' in globals() and len(cols_box) > 0 and TARGET in df.columns:\n",
    "        import numpy as np\n",
    "        n = len(cols_box)\n",
    "        rows = int(np.ceil(n/3))\n",
    "        fig, axes = plt.subplots(rows, 3, figsize=(12, 4*rows))\n",
    "        axes = np.array(axes).reshape(rows, 3)\n",
    "        for i, col in enumerate(cols_box):\n",
    "            r, c = divmod(i, 3)\n",
    "            sns.boxplot(data=df[[col, TARGET]].copy(), x=TARGET, y=col, ax=axes[r, c])\n",
    "            axes[r, c].set_title(f\"Boxplot: {col} por {TARGET}\")\n",
    "        for j in range(n, rows*3):\n",
    "            r, c = divmod(j, 3)\n",
    "            axes[r, c].axis('off')\n",
    "        fig.suptitle('Boxplots 3x3 por clase (Churn)', y=1.02)\n",
    "        fig.tight_layout()\n",
    "        safe_savefig(fig, FIG_DIR / \"boxplots_3x3_por_clase.png\")\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        print('[INFO] Boxplots omitidos: define cols_box y asegúrate de tener df y TARGET.')\n",
    "\n",
    "    # Heatmap de correlaciones\n",
    "    if 'df' in globals():\n",
    "        import numpy as np\n",
    "        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if len(num_cols) > 0:\n",
    "            corr = df[num_cols].corr(numeric_only=True)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "            plt.title('Heatmap de correlaciones')\n",
    "            plt.tight_layout()\n",
    "            safe_savefig(plt.gcf(), FIG_DIR / \"heatmap_correlaciones.png\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            print('[INFO] Heatmap omitido: no hay columnas numéricas.')\n",
    "    else:\n",
    "        print('[INFO] Heatmap omitido: df no definido.')\n",
    "\n",
    "    # Matriz de confusión y ROC/AUC (requiere model, X_test, y_test)\n",
    "    if all(name in globals() for name in ['model','X_test','y_test']):\n",
    "        from sklearn.metrics import ConfusionMatrixDisplay, roc_curve, auc\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm_fig, ax = plt.subplots(figsize=(4,4))\n",
    "        ConfusionMatrixDisplay.from_predictions(y_test, y_pred, normalize='true', ax=ax)\n",
    "        ax.set_title('Matriz de Confusión (normalizada)')\n",
    "        cm_fig.tight_layout()\n",
    "        safe_savefig(cm_fig, FIG_DIR / \"matriz_confusion.png\")\n",
    "        plt.close(cm_fig)\n",
    "\n",
    "        # ROC/AUC si es binario y el modelo soporta predict_proba\n",
    "        try:\n",
    "            proba = model.predict_proba(X_test)[:, 1]\n",
    "            from sklearn.metrics import roc_curve, auc\n",
    "            fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.figure(figsize=(5,4))\n",
    "            plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "            plt.plot([0,1],[0,1],'--')\n",
    "            plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "            plt.title('Curva ROC y AUC'); plt.legend(loc='lower right')\n",
    "            plt.tight_layout()\n",
    "            safe_savefig(plt.gcf(), FIG_DIR / \"roc_curve_auc.png\")\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print('[INFO] ROC/AUC omitido:', e)\n",
    "    else:\n",
    "        print('[INFO] Confusión/ROC omitidos: define model, X_test, y_test.')\n",
    "\n",
    "    # Tablas: classification_report, accuracy, métricas clase positiva\n",
    "    if all(name in globals() for name in ['y_test']):\n",
    "        try:\n",
    "            # Se espera que y_pred exista arriba; si no, recalculamos si hay model y X_test\n",
    "            if 'y_pred' not in globals() and all(name in globals() for name in ['model','X_test']):\n",
    "                y_pred_local = model.predict(X_test)\n",
    "            else:\n",
    "                y_pred_local = y_pred\n",
    "\n",
    "            report_dict = classification_report(y_test, y_pred_local, output_dict=True, zero_division=0)\n",
    "            report_df = pd.DataFrame(report_dict).T\n",
    "            safe_to_csv(report_df, REPORTS_DIR / \"classification_report.csv\")\n",
    "\n",
    "            if all(name in globals() for name in ['X_train','y_train']):\n",
    "                acc_train = accuracy_score(y_train, model.predict(X_train)) if 'model' in globals() else None\n",
    "            else:\n",
    "                acc_train = None\n",
    "            acc_test  = accuracy_score(y_test,  y_pred_local)\n",
    "            acc_df = pd.DataFrame({\n",
    "                'metric': ['accuracy_train','accuracy_test'],\n",
    "                'value':  [acc_train, acc_test]\n",
    "            })\n",
    "            safe_to_csv(acc_df, REPORTS_DIR / \"accuracy_summary.csv\")\n",
    "\n",
    "            labels = sorted(pd.Series(y_test).unique())\n",
    "            if 1 in labels:\n",
    "                pr, rc, f1, _ = precision_recall_fscore_support(y_test, y_pred_local, labels=[1], zero_division=0)\n",
    "                pos_df = pd.DataFrame({'class':['Churn=1'], 'precision':pr, 'recall':rc, 'f1':f1})\n",
    "                safe_to_csv(pos_df, REPORTS_DIR / \"metrics_churn_1.csv\")\n",
    "            else:\n",
    "                print(\"[INFO] Métricas Churn=1 omitidas: no existe clase 1 en y_test.\")\n",
    "        except Exception as e:\n",
    "            print('[WARN] Exportación de tablas omitida por error:', e)\n",
    "    else:\n",
    "        print('[INFO] Tablas omitidas: y_test no definido.')\n",
    "\n",
    "except Exception as e:\n",
    "    print('[WARN] Bloque de export falló:', e)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
